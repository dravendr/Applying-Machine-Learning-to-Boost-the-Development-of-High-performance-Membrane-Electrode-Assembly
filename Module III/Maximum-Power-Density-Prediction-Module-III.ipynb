{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########import packages##########\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import catboost\n",
    "import lightgbm\n",
    "%matplotlib\n",
    "###########wrapping root mean square error for later calls##########\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "###########loading data##########\n",
    "fdata=pd.read_csv('database.csv',encoding=\"gbk\")\n",
    "raw_data=fdata.loc[:,[                     \n",
    "                       'Pt at% in metal element',#0\n",
    "                      'Co at% in metal element',#1\n",
    "                      'total metal mass ratio wt%',#2\n",
    "                      'C wt%',#3\n",
    "                      'Particle diameter （nm）',#4\n",
    "                      'support BET surface area(m2/g)' ,#5\n",
    "                      'Reduction Temperature',#6\n",
    "                      'Reduction Time/min',#7\n",
    "                      'Annealing Temperature',#8\n",
    "                      'ECSA m2/g',#9\n",
    "                      'Mass Activity mA mg-1',#10\n",
    "                      'I/C Ratio(ionomer/catalyst)',#11\n",
    "                      'Area cm2',#12\n",
    "                      'Cathodic Loading Amount mgPt cm-2',#13\n",
    "                      'Anodic Platinum Loading Amount mgPt cm-2',#14\n",
    "                      'Anodic catalyst type x wt% Pt/C',#15\n",
    "                      'membrane thickness',#16\n",
    "                      'Hot Press Temperature',#17\n",
    "                      'Hot Press Time min',#18\n",
    "                      'Hot Press Pressure Mpa',#19\n",
    "                      'Humidity %',#20\n",
    "                      'GDE for 1',#21\n",
    "                      'celltemp',#22\n",
    "                      'Flowing rate of H2 ml min-1',#23\n",
    "                      'flowing rate of cathode gas(O2/air)',#24\n",
    "                      'Back Pressure Mpa',#25\n",
    "                      'Cathode gas oxygen ratio',#26\n",
    "                      'Maximum Power Density mW cm-2'#\n",
    "                        ]]\n",
    "###########handling missing values##########\n",
    "median_raw_data=raw_data.median()\n",
    "dict_median_raw_data=median_raw_data.to_dict()\n",
    "data=raw_data.fillna(dict_median_raw_data)\n",
    "###########data standardization##########\n",
    "standardized_data = (data-np.mean(data,axis=0))/np.std(data,axis=0)\n",
    "###########train test splitting##########\n",
    "raw_param=standardized_data.iloc[:,0:27]\n",
    "raw_power=standardized_data.iloc[:,27]\n",
    "X=raw_param.values.astype(np.float32)\n",
    "y=raw_power.values.astype(np.float32)\n",
    "###########fix random seed for reproducability##########\n",
    "seed=78\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.15,random_state=seed)\n",
    "###########defining a wrapper function for later call from each machine learning algorithms##########\n",
    "def try_different_method(model):\n",
    "    model.fit(X_train,y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    result = model.predict(X_test)\n",
    "    x_prediction_maximum_power_ann=result*np.std(data,axis=0)[27]+np.mean(data,axis=0)[27]\n",
    "    y_real_maximum_power=y_test*np.std(data,axis=0)[27]+np.mean(data,axis=0)[27]\n",
    "    x_prediction_maximum_power_ann_series=pd.Series(x_prediction_maximum_power_ann)\n",
    "    y_real_maximum_power_series=pd.Series(y_real_maximum_power)\n",
    "    ###########evaluating the regression quality##########\n",
    "    corr_ann = round(x_prediction_maximum_power_ann_series.corr(y_real_maximum_power_series), 4)\n",
    "    rmse_val= rmse(x_prediction_maximum_power_ann,y_real_maximum_power)\n",
    "    print(rmse_val)\n",
    "    print(corr_ann)\n",
    "    print(y_real_maximum_power)\n",
    "    ###########generating a figure##########\n",
    "    x_y_x=np.arange(0,2500,100)\n",
    "    x_y_y=np.arange(0,2500,100)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(x_prediction_maximum_power_ann,y_real_maximum_power,color='red',label=algorithm_name)\n",
    "    ax.plot(x_y_x,x_y_y)\n",
    "    plt.legend()\n",
    "    plt.xlabel(u\"Predicted_Maximum_Power mw cm^-2\")\n",
    "    plt.ylabel(u\"Real_Maximum_Power mw cm^-2\")\n",
    "    plt.show()\n",
    "###import machine learning algorithms packages and define the corresponding models####\n",
    "####Decision Tree####\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import metrics\n",
    "model_DecisionTreeRegressor = tree.DecisionTreeRegressor()\n",
    "####Linear Regression####\n",
    "from sklearn import linear_model\n",
    "model_LinearRegression = linear_model.LinearRegression()\n",
    "####Support Vector Regressor####\n",
    "from sklearn import svm\n",
    "model_SVR = svm.SVR()\n",
    "####K Nearest Neighbor####\n",
    "from sklearn import neighbors\n",
    "model_KNeighborsRegressor = neighbors.KNeighborsRegressor()\n",
    "####Random Forest####\n",
    "from sklearn import ensemble\n",
    "model_RandomForestRegressor = ensemble.RandomForestRegressor()\n",
    "####Adaboost####\n",
    "from sklearn import ensemble\n",
    "model_AdaBoostRegressor = ensemble.AdaBoostRegressor()\n",
    "####GBRT####\n",
    "from sklearn import ensemble\n",
    "model_GradientBoostingRegressor = ensemble.GradientBoostingRegressor()\n",
    "####Bagging Regressor ####\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "model_BaggingRegressor = BaggingRegressor()\n",
    "####Extra Tree Regressor####\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "model_ExtraTreeRegressor = ExtraTreeRegressor()\n",
    "####Bayesian Ridge####\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "model_BayesianRidge =BayesianRidge()\n",
    "####Gaussian Process####\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "model_GaussianProcessRegressor=GaussianProcessRegressor()\n",
    "####SGD####\n",
    "from sklearn.linear_model.stochastic_gradient import SGDRegressor\n",
    "model_SGDRegressor=SGDRegressor()\n",
    "####Ridge Regressor####\n",
    "from sklearn.linear_model import Ridge,RidgeCV\n",
    "model_RidgeRegressor=Ridge()\n",
    "####Kernel Ridge####\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "model_KernelRidgeRegressor=KernelRidge()\n",
    "####XGBoost####\n",
    "import xgboost as xgb\n",
    "model_XGboostRegressor=xgb.XGBRegressor()\n",
    "####CatBoost####\n",
    "import catboost\n",
    "model_CatboostRegressor=catboost.CatBoostRegressor()\n",
    "####LightGBM####\n",
    "import lightgbm\n",
    "model_LGBMRegressor=lightgbm.LGBMRegressor()\n",
    "####Lasso Regressor####\n",
    "from sklearn import linear_model\n",
    "model_LassoRegressor=linear_model.LassoCV()\n",
    "####LassoLARS####\n",
    "from sklearn import linear_model\n",
    "model_LARSLassoRegressor=linear_model.LassoLarsCV()\n",
    "####Elastic Net####\n",
    "from sklearn import linear_model\n",
    "model_ElasticNetRegressor=linear_model.ElasticNetCV()\n",
    "####LARS####\n",
    "from sklearn import linear_model\n",
    "model_LARSRegressor=linear_model.LarsCV()\n",
    "####OMP####\n",
    "from sklearn import linear_model\n",
    "model_OMPRegressor=linear_model.OrthogonalMatchingPursuitCV()\n",
    "####ARD####\n",
    "from sklearn import linear_model\n",
    "model_ARDRegressor=linear_model.ARDRegression()\n",
    "####PAR####\n",
    "from sklearn import linear_model\n",
    "model_PARRegressor=linear_model.PassiveAggressiveRegressor()\n",
    "####RANSAC####\n",
    "from sklearn import linear_model\n",
    "model_RANSACRegressor=linear_model.RANSACRegressor()\n",
    "####TSR####\n",
    "from sklearn import linear_model\n",
    "model_TSRRegressor=linear_model.TheilSenRegressor()\n",
    "####Huber####\n",
    "from sklearn import linear_model\n",
    "model_HuberRegressor=linear_model.HuberRegressor()\n",
    "####Polynomial####\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "model_PolynomialRegressor=Pipeline([('poly', PolynomialFeatures(degree=4)),('linear', LinearRegression(fit_intercept=False))])\n",
    "####Linear Support Vector Regressor####\n",
    "from sklearn import svm\n",
    "model_LinearSVR = svm.LinearSVR()\n",
    "####Nu Support Vector Regressor####\n",
    "from sklearn import svm\n",
    "model_NuSVR = svm.NuSVR()\n",
    "####Voting Regressor ####\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "# Build all top scoring models to test them for GridSearch Voting Regressor\n",
    "xgb_estimator = xgb.XGBRegressor(learning_rate= 0.05, max_depth= 7, n_estimators= 1000, reg_alpha=0.01, reg_lambda= 0.1, subsample=0.7)\n",
    "rf_estimator = ensemble.RandomForestRegressor(max_depth=15, n_estimators=400,max_features='auto',min_samples_leaf=2, min_samples_split=2)\n",
    "ada_estimator=ensemble.AdaBoostRegressor(learning_rate=1,loss='square',n_estimators=1000)\n",
    "knn_estimator=neighbors.KNeighborsRegressor(algorithm='ball_tree',leaf_size=2,n_neighbors=8,weights='distance')\n",
    "kernel_ridge_estimator=KernelRidge(alpha=1,coef0=0.01,degree=2,gamma=0.1,kernel='rbf')\n",
    "gb_estimator=ensemble.GradientBoostingRegressor(criterion='friedman_mse',learning_rate=0.1,loss='huber',max_depth=10,max_features='auto',min_samples_split=8,n_estimators=200,subsample=0.6)\n",
    "catboost_estimator=catboost.CatBoostRegressor(learning_rate=0.1,max_depth=5,n_estimators=800,subsample=0.5,verbose=0)\n",
    "lightboost_estimator=lightgbm.LGBMRegressor(reg_alpha=0.1,reg_lambda=0.1,learning_rate=0.01,max_depth=5,n_estimators=4000,subsample=0.5)\n",
    "# Make list of all models\n",
    "estimators_list = [('xgb', xgb_estimator),\n",
    "              ('rf', rf_estimator),\n",
    "                  ('ada',ada_estimator),\n",
    "                  ('knn',knn_estimator),\n",
    "                  ('kernel_ridge',kernel_ridge_estimator),\n",
    "                  ('gb',gb_estimator),\n",
    "                  ('cat',catboost_estimator),\n",
    "                  ('light',lightboost_estimator)]\n",
    "model_VotingRegressor=VotingRegressor(estimators_list)\n",
    "####Stacking Regressor ####\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "model_StackingRegressor = StackingRegressor(estimators_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####Decision Tree####\n",
    "###########defining the parameters dictionary##########\n",
    "param = {'criterion':['mse','mae','friedman_mse'],\n",
    "         'max_depth':range(5,15),\n",
    "         'splitter':['random','best'],\n",
    "         'min_samples_split':range(2,10),\n",
    "         'max_features':[\"auto\", \"sqrt\", \"log2\"]\n",
    "       }\n",
    "grid = GridSearchCV(model_DecisionTreeRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='Decision Tree Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####Support Vector Regressor####\n",
    "###########defining the parameters dictionary##########\n",
    "param = {'kernel':['linear', 'poly', 'rbf'],'max_iter':[100,200,300,400,500,600,700,800,1000,1100,1200,1300,1400,1500],\n",
    "         'degree':[2,3,4],\n",
    "         'gamma':['scale','auto'],\n",
    "         'epsilon':[0.001,0.01,0.1,0.3,0.5,0.7,1],'coef0':[100,200,300,400,500,600,700,800,1000,1100,1200,1300,1400,1500]\n",
    "       }\n",
    "grid = GridSearchCV(model_SVR,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='Support Vector Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####K Nearest Neighbor####\n",
    "###########defining the parameters dictionary##########\n",
    "param = {'n_neighbors':range(1,10),'weights':['uniform','distance'],'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "         'leaf_size':[2,10,20,30,40,50,100],\n",
    "         'p':range(1,10)\n",
    "       }\n",
    "grid = GridSearchCV(model_KNeighborsRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='KNeighbors Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed=2在·\n",
    "np.random.seed(seed)\n",
    "####Random Forest####\n",
    "###########defining the parameters dictionary##########\n",
    "param = {'n_estimators':[200,400,800],\n",
    "         'max_depth':[5,10,15],\n",
    "         'min_samples_split':[2,4,6,8],\n",
    "         'min_samples_leaf':[2,4,8],\n",
    "         'max_features':['auto','sqrt','log2']\n",
    "\n",
    "       }\n",
    "\n",
    "grid = GridSearchCV(model_RandomForestRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='Random Forest Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####Gradient Boost####\n",
    "###########defining the parameters dictionary##########\n",
    "param = {'n_estimators':[200,400,800],\n",
    "         'max_depth':[5,10,15],\n",
    "         'min_samples_split':[2,4,6,8],\n",
    "         'max_features':['auto','sqrt','log2'],\n",
    "         'loss':['ls', 'lad', 'huber', 'quantile'],\n",
    "         'learning_rate':[0.01,0.1,0.2],\n",
    "         'criterion':['friedman_mse'],\n",
    "         'subsample':[0.6,0.8,1]\n",
    "       }\n",
    "grid = GridSearchCV(model_GradientBoostingRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='Gradient Boost Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####SGD####\n",
    "###########defining the parameters dictionary##########\n",
    "param = {'loss':['squared_loss', 'huber','epsilon_insensitive','squared_epsilon_insensitive'],\n",
    "         'penalty':['l2', 'elasticnet'],\n",
    "         'fit_intercept':[True,False],\n",
    "         'max_iter':[500,1000,2000],\n",
    "         'epsilon':[0.001,0.01,0.1,1],\n",
    "         'learning_rate':['invscaling','constant', 'optimal', 'adaptive']\n",
    "       }\n",
    "grid = GridSearchCV(model_SGDRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='Stochastic Gradient Descent Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####Bagging Regressor####\n",
    "###########defining the parameters dictionary##########\n",
    "param = {'n_estimators':[10,50,100,200,400],\n",
    "         'max_samples':[5,10,50,100],\n",
    "         'max_features':[5,10,15,20,27]\n",
    "       }\n",
    "grid = GridSearchCV(model_BaggingRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='Bagging Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####extreme tree####\n",
    "###########defining the parameters dictionary##########\n",
    "param = {\n",
    "         'criterion' : [\"mse\", \"friedman_mse\", \"mae\"],\n",
    "        'splitter' : [ \"best\",'random'],\n",
    "       'max_depth':range(5,15),\n",
    "       'min_samples_split':[2,4,6,8],\n",
    "         'min_samples_leaf':[1,2,4,8]\n",
    "       }\n",
    "grid = GridSearchCV(model_ExtraTreeRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='Extra Tree Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####Kernel Ridge####\n",
    "###########defining the parameters dictionary##########\n",
    "param = {\n",
    "         'alpha':[1,1.5,2],\n",
    "        'kernel':['rbf', 'linear'],\n",
    "        'gamma':[0.1,0.5,1,2],\n",
    "        'degree':[2,3,4],\n",
    "        'coef0':[0.01,0.1,0.5,1,10,50,100,200,500,1000]\n",
    "         \n",
    "       }\n",
    "grid = GridSearchCV(model_KernelRidgeRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='Kernel Ridge Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####Ridge Regressor####\n",
    "###########defining the parameters dictionary##########\n",
    "param = {\n",
    "         'alpha':[0.1,0.2,0.4,0.8,1,1.6,2,4,8],\n",
    "        'solver':['saga','auto']  \n",
    "       }\n",
    "grid = GridSearchCV(model_RidgeRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='Ridge Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####Bayesian Rdige Regressor####\n",
    "###########defining the parameters dictionary##########\n",
    "param = {\n",
    "         'n_iter':[50,100,200,400,800],  \n",
    "       }\n",
    "grid = GridSearchCV(model_BayesianRidge,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='Bayesian Ridge Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####XGboost####\n",
    "###########defining the parameters dictionary##########\n",
    "param = {\n",
    "'learning_rate':[0.01,0.02,0.05,0.1,0.2,1],\n",
    "   'n_estimators':[100,200,400,1000,2000,4000,8000],\n",
    "    'max_depth':[5,7,9,11],\n",
    "    'subsample':[0.5,0.6,0.7,0.8,0.9],\n",
    "    'reg_lambda':[0.1,0.01],#reg_lambda in cloud version\n",
    "    'reg_alpha':[0.1,0.01]#reg_alpha in cloud version\n",
    "       }\n",
    "grid = GridSearchCV(model_XGboostRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='XGBoost Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####Adaboost####\n",
    "###########defining the parameters dictionary##########\n",
    "param = {'n_estimators':[300,500,700,1000],\n",
    "         'learning_rate':[0.01,0.1,1,2],\n",
    "         'loss':[ 'square']\n",
    "       }\n",
    "grid = GridSearchCV(model_AdaBoostRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='AdaBoost Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####Linear Regressor####\n",
    "\n",
    "algorithm_name='Linear Regressor'\n",
    "try_different_method(model_LinearRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####Gaussian Process Regressor####\n",
    "\n",
    "algorithm_name='Gaussian Process Regressor'\n",
    "try_different_method(model_GaussianProcessRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####catboost####\n",
    "###########defining the parameters dictionary##########\n",
    "\n",
    "param = {\n",
    "         'learning_rate':[0.01,0.02,0.1,0.2],\n",
    "       'n_estimators':[100,200,400,800],\n",
    "    'max_depth':[3,5,7,9,11],\n",
    "    'subsample':[0.5,0.7,0.9],\n",
    "    'verbose':[0]\n",
    "       }\n",
    "grid = GridSearchCV(model_CatboostRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='Cat Boost Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####lightboost####\n",
    "###########defining the parameters dictionary##########\n",
    "param = {\n",
    "         'learning_rate':[0.01,0.1,1],\n",
    "   'n_estimators':[100,200,400,1000,2000,4000,8000],\n",
    "    'max_depth':[5,7,9,11],\n",
    "    'subsample':[0.5,0.6,0.7,0.8,0.9],\n",
    "    'lambda':[0.1,0.01],\n",
    "    'alpha':[0.1,0.01]\n",
    "       }\n",
    "grid = GridSearchCV(model_LGBMRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='Light Boost Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####Lasso Regressor####\n",
    "from sklearn import linear_model\n",
    "param = {'eps':[0.001,0.0001,0.01,0.1],\n",
    "         'max_iter':[50,100,200,400,800,1600],  \n",
    "         'n_alphas':[100,200,400,800,1600]\n",
    "         \n",
    "       }\n",
    "grid = GridSearchCV(model_LassoRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='Lasso Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####ElasticNet Regressor####\n",
    "from sklearn import linear_model\n",
    "param = {'eps':[0.001,0.0001,0.01,0.1],\n",
    "         'max_iter':[50,100,200,400,800,1600],  \n",
    "         'n_alphas':[100,200,400,800,1600] \n",
    "       }\n",
    "grid = GridSearchCV(model_ElasticNetRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='Elastic Net Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####LARS Regressor####\n",
    "from sklearn import linear_model\n",
    "param = {\n",
    "         'max_iter':[500,1000,2000,4000,8000,16000],  \n",
    "         'max_n_alphas':[500,1000,2000,] \n",
    "       }\n",
    "grid = GridSearchCV(model_LARSRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='LARS Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####OMP Regressor####\n",
    "from sklearn import linear_model\n",
    "param = {\n",
    "         'max_iter':[500,1000,2000,4000,8000,16000]\n",
    "       }\n",
    "grid = GridSearchCV(model_LARSRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='OMP Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####ARD Regressor####\n",
    "from sklearn import linear_model\n",
    "param = {\n",
    "         'n_iter':[150,300,600,1200,2400],\n",
    "    'alpha_1':[1e-7,1e-6,1e-5],\n",
    "    'alpha_2':[1e-7,1e-6,1e-5],\n",
    "    'lambda_1':[1e-7,1e-6,1e-5],\n",
    "    'lambda_2':[1e-7,1e-6,1e-5]\n",
    "       }\n",
    "grid = GridSearchCV(model_ARDRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='ARD Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####PAR Regressor####\n",
    "from sklearn import linear_model\n",
    "param = {\n",
    "         'C':[0.1,1,10],\n",
    "    'max_iter':[500,1000,1500,2000],\n",
    "    'tol':[0.0001,0.001,0.01,0.1],\n",
    "    'validation_fraction':[0.1,0.3,0.5],\n",
    "    'epsilon':[0.001,0.01,0.1]\n",
    "       }\n",
    "grid = GridSearchCV(model_PARRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='PAR Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####RANSAC Regressor####\n",
    "from sklearn import linear_model\n",
    "param = {\n",
    "         'stop_probability':[0.9,0.99,0.999,0.9999],\n",
    "    'max_trials':[100,500,1000,2000],\n",
    "  \n",
    "       }\n",
    "grid = GridSearchCV(model_RANSACRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='RANSAC Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####TSR Regressor####\n",
    "from sklearn import linear_model\n",
    "param = {\n",
    "         'max_subpopulation':[1000,5000,10000,20000,50000,100000],\n",
    "    'max_iter':[150,300,500,1000,3000,5000],\n",
    "  \n",
    "       }\n",
    "grid = GridSearchCV(model_TSRRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='TSR Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####Huber Regressor####\n",
    "from sklearn import linear_model\n",
    "param = {\n",
    "         'alpha':[0.00001,0.0001,0.001,0.01,0.1],\n",
    "    'max_iter':[100,400,800,1600,3200],\n",
    "  \n",
    "       }\n",
    "grid = GridSearchCV(model_HuberRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='Huber Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####Polynomial Regressor####\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "algorithm_name='Polynomial Regressor'\n",
    "try_different_method(model_PolynomialRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####Linaer Support Vector Regressor####\n",
    "###########defining the parameters dictionary##########\n",
    "param = {'max_iter':[100,200,300,400,500,600,700,800,1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000],\n",
    "         'tol':[0.0001,0.001,0.01,0.1],\n",
    "         'epsilon':[0,0.001,0.01,0.1,0.3,0.5,0.7,1]\n",
    "       }\n",
    "grid = GridSearchCV(model_LinearSVR,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='Linear Support Vector Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####Nu Support Vector Regressor####\n",
    "###########defining the parameters dictionary##########\n",
    "param = {'kernel':['linear', 'poly', 'rbf'],\n",
    "         'degree':[2,3,4],\n",
    "         'gamma':['scale','auto'],\n",
    "         'coef0':[0,10,100,200,400,800,1600]\n",
    "       }\n",
    "grid = GridSearchCV(model_NuSVR,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='NuSupport Vector Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####LARS Lasso Regressor####\n",
    "from sklearn import linear_model\n",
    "param = {\n",
    "         'max_iter':[500,1000,2000,4000,8000,16000],  \n",
    "         'max_n_alphas':[500,1000,2000,] \n",
    "       }\n",
    "grid = GridSearchCV(model_LARSLassoRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='LARS Lasso Regressor'\n",
    "try_different_method(best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
